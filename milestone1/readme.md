# Quick Link

 - [1st Presentation: Design Brief](https://docs.google.com/presentation/d/16h8q5aKKRUvPiBJzeXBbr6RAP-h_7Bh523To2R8XHOw/edit#slide=id.g1cf1efc38e_1_6) 
 - [2nd Presentation: Milestone 1](https://docs.google.com/presentation/d/1XJhfBKSCLkT3wpc6JbNLjI4AcdtmfCjXUWKwkn6lxmw/edit#slide=id.g1d0228a998_1_13)




---

# Assignment 7

Part 1 (In class and on GitHub)

Project presentations: Milestone 1.
 
1. Specify who does what on your team.

2. Provide a reasonably detailed use case or two. Use any medium available for a compelling delivery: video, hands on mock-up experience, simulation on a computer, Wizard-of-Oz demo, etc.

3. Based on the use cases, specify the requirements and the features that the interaction with your device will need to support these use cases: e.g. if there is a speech recognition requirement, what is the desired corpus coverage. If there is a nonverbal behaviors to be recognized, what are they. Same with generation: what verbal and non-verbal expressions have to be generated, how they should be synchronized with the recognition of speech or non-verbal expressions. One way to communicate the logic of many interacting parts in your product is by presenting an FSM that corresponds to your case.

4. Based on the requirements and features, come up with the industrial design, hardware and software architectures of your product. Most of your technologies should be decided upon and already tested by you.

5. Ideally, present some sort of a demo of your use case or of a part of the use case.

6. Create "milestone1" folder in your project's gitHub repository and update it with all the relevant materials necessary for a third-party to reproduce your project. These should include:

  	- Requirements (from item 3).
	- Industrial design, schematics, code (from item 4)
	- Photos and/or vodeos of your use case demo (from item 5).

Next project milestone presentations will be in two weeks after Milestone 1. Milestone 2 presentation must include live demo of a part the product's functionality.


---


#Design Brief
        
 ---
    - Use Cases
      - Scenario 1: Graduate design students trying to get a graphic design job. Carrer fair is coming soon.
      - Scenario 2: non-design major person who wants to change job into graphic design.
      - Scenario 3:
      
    - Specification
      - Feature 1:Able to provide graphic design question.
      - Feature 2:Able to give response base on the length of answer, 
      - Feature 3:Able to give response base on dictionary nagative words vs positive words,
      - Feature 4:Hitory feature to store your response
      - Feature 5:Able to change images/angles/colors based on user's response (E.g. "Waving hands", "Changing eye colors", "Nodding", "Blinking"...)
      - Feature 6:Able to greet users (E.g. "Hello", "Bye")
      - Feature 7:Play sound effects along with Plant-bot's response.
      - Feature 8:HTML-based Speech Recognition. It's cross-platform, responsive use.
      
    - Prototype
    
    - Development
    
---

### Some discussion...

- Additional small things to do:
  - User Research: interviewing those people who are preparing to interview
  - Marketing / Branding / Promotion: A website, a poster, a postcard...



- Thoughts:
  - plant: should be real? or illustration?
    - use the real first
  - Digital (js-based): Can do like an App





